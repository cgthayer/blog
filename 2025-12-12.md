## Playing with Fuzzy AI Ontology Graphs

TIL: GraphDB, VectorDB, Ontology, Embedding Vectors

I was talking to a friend who uses a graphDB in their AI app and has run into an interesting problem. The quality is low because there are often many terms for the same thing, and many terms with multiple meanings depending on context. For example, if you're looking for people to go on a walk with, it's likely that people who like running or hiking are good candidates, but this may not be well represented in your graphDB. There's a traditional way to solve this and more modern one using a vectorDB (weaviate, postgres with pgvector, etc.).

One approach is to create an ontology around this idea of activities and encode how related they are as a number. For example, if I like running maybe that means there's an 80% chance I'll like walking (even though I didn't say so), and if I like hiking perhaps there's a 90% chance I'll like walking. Plus, in the other direction, if I like walking I'm also 90% likely to like hiking.

![graphdb-thoughts.excalidraw|800](graphdb-thoughts.excalidraw.md)


But wait, if I like hiking, am I likely to like running? There's no arrow between those, and our graph implies there's a relationship there, but we don't know that we can safely infer such things. Plus, do we be conservative and say it's 80% likely or do we be optimistic and say 90%, or average the two at 85%. We might even be more conservative and "walk the graph" and multiple .8*.9 to get 72% likelihood (since we don't have direct evidence). Plus, we know that this isn't purely bidirectional, so someone who said they like "outdoor activities" might also like walking 70% of the time, but someone who likes walking is 91% likely to like "outdoor activities"...



```python
"""
Simple example: Calculating embeddings and semantic distances
For developers learning about vector databases and similarity search
"""

import chromadb
from chromadb.utils import embedding_functions
import numpy as np


def main():
    embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="average_word_embeddings_glove.6B.300d"  # Word-optimized model
    )
    data = ["walk", "run", "hike"]
    embeddings = embedding_fn(data[:3])
    print(f"Embedding vector eg: sz={len(embeddings[0])}:\n  {embeddings[0][:5]}...\n")
    print("Pairwise cosine similarities (0-1, 1.0=same):")
    for i in range(3):
        for j in range(3):
            sim = cosine_similarity(embeddings[i], embeddings[j])
            print(f"* {data[i]:>6} <-> {data[j]:<6}: {sim:.4f}")


def cosine_similarity(vec1, vec2):
    dot_product = np.dot(vec1, vec2)
    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)
    return dot_product / norm_product


if __name__ == "__main__":
    main()

```

Of course, it's great if we can enumerate the nodes we need in the graph, but often there are too many terms we might not know. Consider that someone may say "I like running" or "I'm a runner" or "I go for runs" and simply searching for "running" as an interest will miss 2 terms out of three of these. Stemming and other tricks might help but they're brittle. We always come across data we didn't expect, e.g. we might read "I was a sprinter on the track team" or "I like sprinting" and miss that they have an interest in "running". LLMs are great exactly this kind of problem. For an application we may not want to use a full prompt and LLM API call, but luckily we can use embeddings and vectorDBs to help.

CODE

A newer way to look at this problem is to leverage ML. We have vectorDBs and embeddings, which give us a nice calculation of "conceptual distance". What this means is, that we can get these kinda numbers "for free" without necessarily building this graph out. Plus vectorDBs are amazing at quickly giving us the top-K of similar items. Embedding models have done the work of figuring out, across huge corpuses of text, what these words and concepts mean, especially in relation to each other. And that's probably good enough for a lot of use cases.

There's a caveat here, which is to say that words without context can be dangerous. I worked in web search and we used to say "Fencing can be a sport, the stuff the borders your house, or what you do with stolen goods". So, depending on your embedding model, you may want to calculate from "I like the activity walking" and "I like the activity running" as opposed to using the bare words.

CODE

Advanced: meaning (as represented in the embeddings) and intent (as represented in the hand generated graph) are very different especially given the particular domain you're working in. e.g. people who like competitive swimming may be the exact opposite of those who like water ballet. In a real production system you'd either train your own embedding model (if there's enough data), or mix and match the two ideas so you have some control. Also, for speed, there's a trade-off of pre-generating a more connected (or complete) graph so that you only need a single graphdb query versus a multi-hop query. Since a complete graph is O(n^2) that only makes sense for small(ish) data.

End thought: it's all about the details, so you should always test. A vectorDB search is fast, but if you need accuracy and control then the right approach may be building a graph and calculating these weights yourself and doing several queries to get answers.

---
Tech Note: we used a couple models, so beware that the embedding vectors between them are not compatible. e.g. never compare vectors from a word model against a sentence model.

Thanks Dick King for the fencing examples

