<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"><head>
  <meta charset="utf-8">
  
    <meta http-equiv="content-language" content="en">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color">

  
  
    <title>Modeling The Fuzzy - from GraphDBs to Embeddings to VectorDBs &middot; Learn Tinker Share Blog</title>
    <meta name="title" content="Modeling The Fuzzy - from GraphDBs to Embeddings to VectorDBs &middot; Learn Tinker Share Blog">
  

  
  
    <meta name="description" content="A blog about AI engineering, development, and best practices">
  
  
  
  
  <link rel="canonical" href="https://thayer-blog.b2si.com/posts/play-with-embeddings/">
  

  
  
    <meta name="author" content="Charles Thayer">
  
  

  
  <meta property="og:url" content="https://thayer-blog.b2si.com/posts/play-with-embeddings/">
  <meta property="og:site_name" content="Learn Tinker Share Blog">
  <meta property="og:title" content="Modeling The Fuzzy - from GraphDBs to Embeddings to VectorDBs">
  <meta property="og:description" content="From GraphDB Ontologies to Embeddings: Modeling Fuzzy Relationships # Keywords: GraphDB, VectorDB, Ontology, Embedding Vectors
I was talking to a friend who uses a graphDB in their AI app and has run into an interesting problem. The quality is low because there are often many terms for the same thing, and many terms with multiple meanings depending on context. For example, if you’re looking for people to go on a walk with, it’s likely that people who like running or hiking are good candidates, but this may not be well represented in your graphDB. There’s a traditional way to solve this and more modern one using a vectorDB (weaviate, postgres with pgvector, etc.).">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-12-12T11:53:10-08:00">
    <meta property="article:modified_time" content="2025-12-12T11:53:10-08:00">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Modeling The Fuzzy - from GraphDBs to Embeddings to VectorDBs">
  <meta name="twitter:description" content="From GraphDB Ontologies to Embeddings: Modeling Fuzzy Relationships # Keywords: GraphDB, VectorDB, Ontology, Embedding Vectors
I was talking to a friend who uses a graphDB in their AI app and has run into an interesting problem. The quality is low because there are often many terms for the same thing, and many terms with multiple meanings depending on context. For example, if you’re looking for people to go on a walk with, it’s likely that people who like running or hiking are good candidates, but this may not be well represented in your graphDB. There’s a traditional way to solve this and more modern one using a vectorDB (weaviate, postgres with pgvector, etc.).">

  
  
  
  
    
      
    
  
    
      
    
  
    
      
    
  
  
    
  

  
  
  
  
  
  

  

  
  
  
  
  
  
  
    
  
  
    
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="/css/main.bundle.min.c4828b5f999b6b65b4c7242c5559a3bb7536d202449d2d2c85a41e6b30cfbafcc2ceb2424fb681666ba32f05f9759221b3f9c0f1f8ed232ad59ac737fe79048f.css"
    integrity="sha512-xIKLX5mba2W0xyQsVVmju3U20gJEnS0shaQeazDPuvzCzrJCT7aBZmujLwX5dZIhs/nA8fjtIyrVmsc3/nkEjw==">

  
  
  <script
    type="text/javascript"
    src="/js/appearance.min.6f41174b3a05b680820fe08cadbfa5fb7a7ca347b76a0955cdc68b9d8aca1ce24f0547e138cea33bcc7904d551a90afcb1cc7f2d9fe8557075d501419046c08c.js"
    integrity="sha512-b0EXSzoFtoCCD&#43;CMrb&#43;l&#43;3p8o0e3aglVzcaLnYrKHOJPBUfhOM6jO8x5BNVRqQr8scx/LZ/oVXB11QFBkEbAjA=="></script>
  
  
  
  
  
  
    
    <script src="/lib/zoom/zoom.min.umd.a527109b68c082a70f3697716dd72a9d5aa8b545cf800cecbbc7399f2ca6f6e0ce3e431f2062b48bbfa47c9ea42822714060bef309be073f49b9c0e30d318d7b.js" integrity="sha512-pScQm2jAgqcPNpdxbdcqnVqotUXPgAzsu8c5nyym9uDOPkMfIGK0i7&#43;kfJ6kKCJxQGC&#43;8wm&#43;Bz9JucDjDTGNew=="></script>
  

  
  
  
    
  
  
    
  
  
    
  
  
  
  
  
  
    
    <script
      defer
      type="text/javascript"
      id="script-bundle"
      src="/js/main.bundle.min.b16d807a513bd375edb24c501502c85cc94dfdaf3cf1979d51e2362e4eb5deaeab801c26116a5ee436a7ac00f27d244f7778458fee832a0cbb274ee23900d6bf.js"
      integrity="sha512-sW2AelE703XtskxQFQLIXMlN/a888ZedUeI2Lk613q6rgBwmEWpe5DanrADyfSRPd3hFj&#43;6DKgy7J07iOQDWvw=="
      data-copy="Copy"
      data-copied="Copied"></script>
  

  
  

<script src="/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>


























  

  

  

  

  








  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
  

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Posts",
    "name": "Modeling The Fuzzy - from GraphDBs to Embeddings to VectorDBs",
    "headline": "Modeling The Fuzzy - from GraphDBs to Embeddings to VectorDBs",
    
    "inLanguage": "en",
    "url" : "https://thayer-blog.b2si.com/posts/play-with-embeddings/",
    "author" : {
      "@type": "Person",
      "name": "Charles Thayer"
    },
    "copyrightYear": "2025",
    "dateCreated": "2025-12-12T11:53:10-08:00",
    "datePublished": "2025-12-12T11:53:10-08:00",
    
    "dateModified": "2025-12-12T11:53:10-08:00",
    
    
    
    "mainEntityOfPage": "true",
    "wordCount": "1336"
  }]
  </script>



  
  
    




  

  
  

  
  

  
  

  
  
</head>


















  
  <body class="flex flex-col h-screen m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32 text-lg bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral bf-scrollbar">
    <div id="the-top" class="absolute flex self-center">
      <a
        class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content">
        <span class="font-bold text-primary-600 pe-2 dark:text-primary-400">&darr;</span>
        Skip to main content
      </a>
    </div>
    
    
      <div class="main-menu flex items-center w-full gap-2 p-1 pl-0">
  
  
    <a href="/" class="text-base font-medium truncate min-w-0 shrink">
      Learn Tinker Share Blog
    </a>
  
  <div class="flex items-center ms-auto">
    <div class="hidden md:flex">
      <nav class="flex items-center gap-x-5 h-12">
  

  

  

  
    <button
      id="search-button"
      aria-label="Search"
      class="text-base bf-icon-color-hover"
      title="Search (/)">
      <span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
    </button>
  

  
    <div class="flex items-center">
      <button
        id="appearance-switcher"
        aria-label="Dark mode switcher"
        type="button"
        class="text-base bf-icon-color-hover">
        <div class="flex items-center justify-center dark:hidden">
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span>
        </div>
        <div class="items-center justify-center hidden dark:flex">
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
        </div>
      </button>
    </div>
  
</nav>



    </div>
    <div class="flex md:hidden">
      <div class="flex items-center h-14 gap-4">
  
    <button
      id="search-button-mobile"
      aria-label="Search"
      class="flex items-center justify-center bf-icon-color-hover"
      title="Search (/)">
      <span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
    </button>
  

  
    <button
      id="appearance-switcher-mobile"
      type="button"
      aria-label="Dark mode switcher"
      class="flex items-center justify-center text-neutral-900 hover:text-primary-600 dark:text-neutral-200 dark:hover:text-primary-400">
      <div class="dark:hidden">
        <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span>
      </div>
      <div class="hidden dark:block">
        <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
      </div>
    </button>
  

  
</div>







    </div>
  </div>
</div>





    
    <div class="relative flex flex-col grow">
      <main id="main-content" class="grow">
        
  
  <article>
    
    

    
    <header id="single_header" class="mt-5 max-w-prose">
      
      <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        Modeling The Fuzzy - from GraphDBs to Embeddings to VectorDBs
      </h1>
      <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
        





  
  



  

  
  
  
    
  

  

  
    
  

  

  
    
  

  
    
  

  

  

  

  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2025-12-12T11:53:10-08:00">12 December 2025</time><span class="px-2 text-primary-500">&middot;</span><span>1336 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">7 mins</span>
    

    
    
  </div>

  

  
  
    <div class="flex flex-row flex-wrap items-center">
      
        
      
        
          
        
      
        
          
        
      
    </div>
  

  
  



      </div>
      
        
  
  
  
  
  
  

  

  
    
    
<div class="flex author">
  
  <div class="place-self-center">
    
      <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
        Author
      </div>
      <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
        Charles Thayer
      </div>
    
    
      <div class="text-sm text-neutral-700 dark:text-neutral-400">Software engineer exploring AI, development, and best practices</div>
    
    <div class="text-2xl sm:text-lg">
</div>
  </div>
</div>

  

  

  
    <div class="mb-5"></div>
  

      
    </header>

    
    <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
      
      
      
      
      
        <div class="order-first lg:ms-auto px-0 lg:order-last lg:ps-8 lg:max-w-2xs">
          <div class="toc ps-5 print:hidden lg:sticky lg:top-10">
            <details
  open
  id="TOCView"
  class="toc-right mt-0 overflow-y-auto overscroll-contain bf-scrollbar rounded-lg -ms-5 ps-5 pe-2 hidden lg:block">
  <summary
    class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 -ms-5 ps-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    Table of Contents
  </summary>
  <div
    class="min-w-[220px] py-2 border-dotted border-s-1 -ms-5 ps-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#end-notes">End Notes:</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</details>
<details class="toc-inside mt-0 overflow-hidden rounded-lg -ms-5 ps-5 lg:hidden">
  <summary
    class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 -ms-5 ps-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    Table of Contents
  </summary>
  <div
    class="py-2 border-dotted border-neutral-300 border-s-1 -ms-5 ps-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#end-notes">End Notes:</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</details>


<script>
  (function () {
    'use strict'

    const SCROLL_OFFSET_RATIO = 0.33
    const TOC_SELECTOR = '#TableOfContents'
    const ANCHOR_SELECTOR = '.anchor'
    const TOC_LINK_SELECTOR = 'a[href^="#"]'
    const NESTED_LIST_SELECTOR = 'li ul'
    const ACTIVE_CLASS = 'active'
    let isJumpingToAnchor = false

    function getActiveAnchorId(anchors, offsetRatio) {
      const threshold = window.scrollY + window.innerHeight * offsetRatio
      const tocLinks = [...document.querySelectorAll('#TableOfContents a[href^="#"]')]
      const tocIds = new Set(tocLinks.map(link => link.getAttribute('href').substring(1)))

      if (isJumpingToAnchor) {
        for (let i = 0; i < anchors.length; i++) {
          const anchor = anchors[i]
          if (!tocIds.has(anchor.id)) continue
          const top = anchor.getBoundingClientRect().top + window.scrollY
          if (Math.abs(window.scrollY - top) < 100) {
            return anchor.id
          }
        }
      }

      for (let i = anchors.length - 1; i >= 0; i--) {
        const top = anchors[i].getBoundingClientRect().top + window.scrollY
        if (top <= threshold && tocIds.has(anchors[i].id)) {
          return anchors[i].id
        }
      }
      return anchors.find(anchor => tocIds.has(anchor.id))?.id || ''
    }

    function updateTOC({ toc, anchors, links, scrollOffset, collapseInactive }) {
      const activeId = getActiveAnchorId(anchors, scrollOffset)
      if (!activeId) return

      links.forEach(link => {
        const isActive = link.getAttribute('href') === `#${activeId}`
        link.classList.toggle(ACTIVE_CLASS, isActive)

        if (collapseInactive) {
          const ul = link.closest('li')?.querySelector('ul')
          if (ul) ul.style.display = isActive ? '' : 'none'
        }
      })

      if (collapseInactive) {
        const activeLink = toc.querySelector(`a[href="#${CSS.escape(activeId)}"]`)
        let el = activeLink
        while (el && el !== toc) {
          if (el.tagName === 'UL') el.style.display = ''
          if (el.tagName === 'LI') el.querySelector('ul')?.style.setProperty('display', '')
          el = el.parentElement
        }
      }
    }

    function initTOC() {
      const toc = document.querySelector(TOC_SELECTOR)
      if (!toc) return

      const collapseInactive = false
      const anchors = [...document.querySelectorAll(ANCHOR_SELECTOR)]
      const links = [...toc.querySelectorAll(TOC_LINK_SELECTOR)]

      if (collapseInactive) {
        toc.querySelectorAll(NESTED_LIST_SELECTOR).forEach(ul => ul.style.display = 'none')
      }

      links.forEach(link => {
        link.addEventListener('click', () => {
          isJumpingToAnchor = true
        })
      })

      const config = {
        toc,
        anchors,
        links,
        scrollOffset: SCROLL_OFFSET_RATIO,
        collapseInactive
      }

      window.addEventListener('scroll', () => updateTOC(config), { passive: true })
      window.addEventListener('hashchange', () => updateTOC(config), { passive: true })

      updateTOC(config)
    }

    document.readyState === 'loading'
      ? document.addEventListener('DOMContentLoaded', initTOC)
      : initTOC()
  })()
</script>


          </div>
        </div>
      


      <div class="min-w-0 min-h-0 max-w-fit">
        

        <div class="article-content max-w-prose mb-20">
          
<h1 class="relative group">From GraphDB Ontologies to Embeddings: Modeling Fuzzy Relationships
    <div id="from-graphdb-ontologies-to-embeddings-modeling-fuzzy-relationships" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#from-graphdb-ontologies-to-embeddings-modeling-fuzzy-relationships" aria-label="Anchor">#</a>
    </span>
    
</h1>
<p>Keywords: GraphDB, VectorDB, Ontology, Embedding Vectors</p>
<p>I was talking to a friend who uses a graphDB in their AI app and has run into an interesting problem. The quality is low because there are often many terms for the same thing, and many terms with multiple meanings depending on context. For example, if you&rsquo;re looking for people to go on a walk with, it&rsquo;s likely that people who like running or hiking are good candidates, but this may not be well represented in your graphDB. There&rsquo;s a traditional way to solve this and more modern one using a vectorDB (weaviate, postgres with pgvector, etc.).</p>
<p>One approach is to create an ontology around this idea of activities and encode how related they are as a number. For example, if I like running maybe that means there&rsquo;s an 80% chance I&rsquo;ll like walking (even though I didn&rsquo;t say so), and if I like hiking perhaps there&rsquo;s a 90% chance I&rsquo;ll like walking. Plus, in the other direction, if I like walking I&rsquo;m also 90% likely to like hiking.</p>
<p><a href="graphdb-thoughts.excalidraw.md" >IMG-SOURCE</a>
<figure><img
    class="my-0 rounded-md"
    loading="lazy"
    decoding="async"
    fetchpriority="low"
    alt="Diagram 1"
    src="/images/graphdb-thoughts.excalidraw.png"
    ></figure>
</p>
<p>But wait, if I like hiking, am I likely to like running? There&rsquo;s no arrow between those, and our graph implies there&rsquo;s a relationship there, but we don&rsquo;t know that we can safely infer such things. Plus, should we be conservative and say it&rsquo;s 80% likely or should we be optimistic and say 90%, or average the two at 85%? We might even be more conservative and &ldquo;walk the graph&rdquo; and multiply .8 * .9 to get 72% likelihood (See picture 3 and 4). Plus, we know that this isn&rsquo;t purely bidirectional, so someone who said they like &ldquo;outdoor activities&rdquo; might also like walking 70% of the time, but someone who likes walking may be 91% likely to like &ldquo;outdoor activities&rdquo;&hellip;</p>
<p>For fun here&rsquo;s some naive code. We can imagine inferring a few hops, reviewing dijkstra&rsquo;s algo, etc.</p>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>graph <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#34;running&#34;</span>, <span style="color:#e6db74">&#34;walking&#34;</span>): <span style="color:#ae81ff">0.80</span>, (<span style="color:#e6db74">&#34;walking&#34;</span>, <span style="color:#e6db74">&#34;running&#34;</span>): <span style="color:#ae81ff">0.80</span>,
</span></span><span style="display:flex;"><span>    (<span style="color:#e6db74">&#34;hiking&#34;</span>, <span style="color:#e6db74">&#34;walking&#34;</span>): <span style="color:#ae81ff">0.90</span>, (<span style="color:#e6db74">&#34;walking&#34;</span>, <span style="color:#e6db74">&#34;hiking&#34;</span>): <span style="color:#ae81ff">0.90</span>,
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">score</span>(a, b):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (a, b) <span style="color:#f92672">in</span> graph:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;direct&#34;</span>, <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>graph[(a, b)]<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    shared <span style="color:#f92672">=</span> [x <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> [<span style="color:#e6db74">&#34;running&#34;</span>, <span style="color:#e6db74">&#34;hiking&#34;</span>, <span style="color:#e6db74">&#34;walking&#34;</span>] <span style="color:#66d9ef">if</span> (a, x) <span style="color:#f92672">in</span> graph]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> shared:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;one-hop&#34;</span>, <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>graph[(a, shared[<span style="color:#ae81ff">0</span>])] <span style="color:#f92672">*</span> graph[(shared[<span style="color:#ae81ff">0</span>], b)]<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;no path&#34;</span>, <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;running → walking:&#34;</span>, score(<span style="color:#e6db74">&#34;running&#34;</span>, <span style="color:#e6db74">&#34;walking&#34;</span>))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;hiking → walking:&#34;</span>, score(<span style="color:#e6db74">&#34;hiking&#34;</span>, <span style="color:#e6db74">&#34;walking&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;running → hiking:&#34;</span>, score(<span style="color:#e6db74">&#34;running&#34;</span>, <span style="color:#e6db74">&#34;hiking&#34;</span>))</span></span></code></pre></div></div>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>running → walking: (&#39;direct&#39;, &#39;0.8000&#39;)
</span></span><span style="display:flex;"><span>hiking → walking: (&#39;direct&#39;, &#39;0.9000&#39;)
</span></span><span style="display:flex;"><span>running → hiking: (&#39;one-hop&#39;, &#39;0.7200&#39;)</span></span></code></pre></div></div>
<p>Of course, it&rsquo;s great if we can enumerate the nodes we need in the graph, but often there are too many terms we might not know. Consider that someone may say &ldquo;I like running&rdquo; or &ldquo;I&rsquo;m a runner&rdquo; or &ldquo;I go for runs&rdquo; and simply searching for &ldquo;running&rdquo; as an interest will miss 2 terms out of three of these. Stemming and other tricks might help but they&rsquo;re brittle. We always come across data we didn&rsquo;t expect, e.g. we might read &ldquo;I was a sprinter on the track team&rdquo; or &ldquo;I like sprinting&rdquo; and miss that they have an interest in &ldquo;running&rdquo;.</p>
<p>A newer way to look at this problem is to leverage ML. LLMs are great at exactly this kind of problem. For an application we may not want to use a full prompt and LLM API call, but luckily we can use embeddings and vectorDBs to help. Let&rsquo;s quickly look at the word embeddings for walk, run, hike and see what we get in terms of cosine distances:</p>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> chromadb
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> chromadb.utils <span style="color:#f92672">import</span> embedding_functions
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>():
</span></span><span style="display:flex;"><span>    embedding_fn <span style="color:#f92672">=</span> embedding_functions<span style="color:#f92672">.</span>SentenceTransformerEmbeddingFunction(
</span></span><span style="display:flex;"><span>        model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;average_word_embeddings_glove.6B.300d&#34;</span>  <span style="color:#75715e"># Word-optimized model</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;walk&#34;</span>, <span style="color:#e6db74">&#34;run&#34;</span>, <span style="color:#e6db74">&#34;hike&#34;</span>]
</span></span><span style="display:flex;"><span>    embeddings <span style="color:#f92672">=</span> embedding_fn(data)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Embedding vector eg: sz=</span><span style="color:#e6db74">{</span>len(embeddings[<span style="color:#ae81ff">0</span>])<span style="color:#e6db74">}</span><span style="color:#e6db74">, looks like: </span><span style="color:#e6db74">{</span>embeddings[<span style="color:#ae81ff">0</span>][:<span style="color:#ae81ff">5</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">...&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Pairwise cosine similarities (0-1, 1.0=same):&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(data)):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>, len(data)):
</span></span><span style="display:flex;"><span>            sim <span style="color:#f92672">=</span> cosine_similarity(embeddings[i], embeddings[j])
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;* </span><span style="color:#e6db74">{</span>data[i]<span style="color:#e6db74">:</span><span style="color:#e6db74">&gt;6</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> &lt;-&gt; </span><span style="color:#e6db74">{</span>data[j]<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;6</span><span style="color:#e6db74">}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{</span>sim<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">cosine_similarity</span>(vec1, vec2):
</span></span><span style="display:flex;"><span>    dot_product <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>dot(vec1, vec2)
</span></span><span style="display:flex;"><span>    norm_product <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>norm(vec1) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>norm(vec2)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> dot_product <span style="color:#f92672">/</span> norm_product
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()</span></span></code></pre></div></div>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>Embedding vector eg: sz=300, looks like: [-0.014619 -0.17277  -0.11171   0.31864  -0.52504 ]...
</span></span><span style="display:flex;"><span>Pairwise cosine similarities (0-1, 1.0=same):
</span></span><span style="display:flex;"><span>*   walk &lt;-&gt; run   : 0.4750
</span></span><span style="display:flex;"><span>*   walk &lt;-&gt; hike  : 0.3058
</span></span><span style="display:flex;"><span>*    run &lt;-&gt; hike  : 0.2077</span></span></code></pre></div></div>
<p>Interesting:. This model finds <code>walk</code> and <code>run</code> to be the most similar, <code>walk</code> and <code>hike</code> the next, and <code>hike</code> and <code>run</code> the least similar</p>
<p>Today, we have embeddings, which give us a nice calculation of &ldquo;conceptual distance&rdquo;. What this means is we can get these &ldquo;relationship&rdquo; numbers &ldquo;for free&rdquo; without necessarily building this graph out. Plus vectorDBs are amazing at quickly giving us the top-K of similar items. Embedding models have done the work of figuring out, across huge corpuses of text, what these words and concepts mean, especially in relation to each other. And that&rsquo;s probably good enough for a lot of use cases.</p>
<p>There&rsquo;s a caveat here, which is to say that words without context can be dangerous. I worked in web search and we used to say &ldquo;Fencing can be a sport, the stuff that borders your house, or what you do with stolen goods&rdquo;. So, depending on your embedding model, you may want to calculate from full sentences such as &ldquo;I like the activity walking&rdquo; and &ldquo;I like the activity running&rdquo; as opposed to using the bare words.</p>
<p>A quick change to the more popular Sentence model &ldquo;all-MiniLLM-L6-v2&rdquo;:</p>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>    embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
</span></span><span style="display:flex;"><span>        model_name=&#34;all-MiniLM-L6-v2&#34;  # Sentence transformer model
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    data = [&#34;I like to walk&#34;, &#34;I like to run&#34;, &#34;I like to hike&#34;]
</span></span><span style="display:flex;"><span>    embeddings = embedding_fn(data[:3])</span></span></code></pre></div></div>
<div class="highlight-wrapper"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>Embedding vector eg: sz=384, looks like: [-0.06094085 -0.05805941  0.03494389  0.09246249  0.0638584 ]...
</span></span><span style="display:flex;"><span>Pairwise cosine similarities (0-1, 1.0=same):
</span></span><span style="display:flex;"><span>* I like to walk &lt;-&gt; I like to run: 0.6254
</span></span><span style="display:flex;"><span>* I like to walk &lt;-&gt; I like to hike: 0.7236
</span></span><span style="display:flex;"><span>* I like to run &lt;-&gt; I like to hike: 0.5118</span></span></code></pre></div></div>
<p>Interesting. This model has a different perspective, which could be the model <strong>or</strong> the context of interests and preferences (or both).</p>
<p>The most powerful and robust feature here is that we can handle almost any input without the need to pre-calculate our graph and weights. If we have an enumeration of categories of people&rsquo;s favorite activities, and we see an event category that&rsquo;s new to us, we can make an educated guess about how to map them, or use the embedding as input to our ranking. Meaning, if we put event descriptions into our vectorDB, then search for &ldquo;I like to walk&rdquo;, then a hiking event should score well.</p>
<p>Of course, a combination of the two concepts would be needed in a real system since &ldquo;interests&rdquo; isn&rsquo;t the same as &ldquo;semantic meaning&rdquo;. Here we controlled the sentence, but if you put in &ldquo;I hate to walk&rdquo; it turns out that sentence scores 0.7697 from &ldquo;I like to walk&rdquo; because these are close in latent space although one part of the vector is pointing in the opposite direction. If you can afford the latency of calling a foundational LLM with a prompt, it would handle such a case nicely.</p>
<p>My friend is still playing around with his code, but running through these ideas gave him some fun approaches to think about. Matching, recommendation systems, and ranking are always interesting to play with and there&rsquo;s always more to explore.</p>
<p>What&rsquo;s your experience on these topics?  Feel free to ask questions in the comments, or let me know what other topics you&rsquo;d like to know about. I always monitor them for awhile after publishing.</p>
<hr>

<h3 class="relative group">End Notes:
    <div id="end-notes" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#end-notes" aria-label="Anchor">#</a>
    </span>
    
</h3>
<ul>
<li>Production quality is all about the details, so you should always test and benchmark. A vectorDB search is fast, but if you need accuracy and control then the right approach may be building a graph and calculating these weights yourself (doing several queries to get answers).</li>
<li>At the time of writing, Weaviate was the only vectorDB I found that directly supports graphDB features.</li>
<li>We used a couple models, so beware that the embedding vectors between them are not compatible. e.g. never compare vectors from a word model against a sentence model.</li>
</ul>
<p>Thanks Richard King for the fencing examples  ;-)</p>

          
          
          
        </div>
        
        

        

        

      </div>

      
      
        
        
          
          
        
        
        
        <script
          type="text/javascript"
          src="/js/page.min.54b6f4371722649edbe871e431d8670d670878c22be8f36e229fe53cc9b786fe25a834def5e6de621f7a3e37b72bc8cd73839aa5ed907ed6cbd45cd3e1b0fa20.js"
          integrity="sha512-VLb0NxciZJ7b6HHkMdhnDWcIeMIr6PNuIp/lPMm3hv4lqDTe9ebeYh96Pje3K8jNc4Oape2QftbL1FzT4bD6IA=="
          data-oid="views_posts/play-with-embeddings.md"
          data-oid-likes="likes_posts/play-with-embeddings.md"></script>
      
    </section>

    
    <footer class="pt-8 max-w-prose print:hidden">
      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600">
      <div class="flex justify-between pt-3">
        <span class="flex flex-col">
          
            <a
              class="flex text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
              href="/posts/welcome/">
              <span class="leading-6">
                <span class="inline-block rtl:rotate-180">&larr;</span>&ensp;Welcome
              </span>
            </a>
            
              <span class="ms-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400">
                <time datetime="2025-11-22T11:53:10-08:00">22 November 2025</time>
              </span>
            
          
        </span>
        <span class="flex flex-col items-end">
          
            <a
              class="flex text-right text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
              href="/posts/real-ai-engineer-differentiator/">
              <span class="leading-6">
                AI SW Engineers: You're Not Prod-Ready Until You Have This&ensp;<span class="inline-block rtl:rotate-180">&rarr;</span>
              </span>
            </a>
            
              <span class="me-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400">
                <time datetime="2026-01-09T13:34:01-08:00">9 January 2026</time>
              </span>
            
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

        


  






<div
  id="scroll-to-top"
  class="fixed bottom-6 end-6 z-50 transform translate-y-4 opacity-0 duration-200">
  <a
    href="#the-top"
    class="pointer-events-auto flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top"
    title="Scroll to top">
    &uarr;
  </a>
</div>

      </main><footer id="site-footer" class="py-10 print:hidden">
  
  
  <div class="flex items-center justify-between">
    
    
      <p class="text-sm text-neutral-500 dark:text-neutral-400">
          &copy;
          2026
          Charles Thayer
      </p>
    

    
    
      <p class="text-xs text-neutral-500 dark:text-neutral-400">
        
        
        Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
          href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
          href="https://blowfish.page/" target="_blank" rel="noopener noreferrer">Blowfish</a>
      </p>
    
  </div>
  
    <script>
      mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
        margin: 24,
        background: "rgba(0,0,0,0.5)",
        scrollOffset: 0,
      });
    </script>
  
  
  
  <script
    type="text/javascript"
    src="/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js"
    integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh] z-500"
  data-url="https://thayer-blog.b2si.com/">
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800">
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          <span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0">
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)">
        <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

    </div>
  </body>
  
</html>
