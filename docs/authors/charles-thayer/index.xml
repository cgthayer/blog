<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>[&#34;Charles Thayer&#34;] on Learn Tinker Share Blog</title>
    <link>https://thayer-blog.b2si.com/authors/charles-thayer/</link>
    <description>Recent content in [&#34;Charles Thayer&#34;] on Learn Tinker Share Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Â© 2026 Charles Thayer</copyright>
    <lastBuildDate>Fri, 09 Jan 2026 13:34:01 -0800</lastBuildDate><atom:link href="https://thayer-blog.b2si.com/authors/charles-thayer/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>AI SW Engineers: You&#39;re Not Prod-Ready Until You Have This</title>
      <link>https://thayer-blog.b2si.com/posts/real-ai-engineer-differentiator/</link>
      <pubDate>Fri, 09 Jan 2026 13:34:01 -0800</pubDate>
      
      <guid>https://thayer-blog.b2si.com/posts/real-ai-engineer-differentiator/</guid>
      <description>&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt; become prod-ready and bullet-proof using &lt;strong&gt;agentic evals&lt;/strong&gt; testing.&lt;/p&gt;&#xA;&lt;p&gt;Those of us who write AI applications fall into two categories: the nervous and the prod-ready. It&amp;rsquo;s usually based on whether you have run a production system, with real users, over time. When you have, you learn the first key differentiator is &amp;ldquo;evals&amp;rdquo;, but not specifically traditional ML evals. Simply put, it&amp;rsquo;s whether you have an automated way to test and score the &lt;em&gt;&lt;strong&gt;quality&lt;/strong&gt;&lt;/em&gt; of your systems.&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
